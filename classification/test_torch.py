import torch
import sys

print("=" * 60)
print("ğŸ” PyTorch ç¯å¢ƒæ£€æµ‹è„šæœ¬")
print("=" * 60)

# æ£€æŸ¥ PyTorch æ˜¯å¦å¯å¯¼å…¥
try:
    print(f"âœ… PyTorch ç‰ˆæœ¬: {torch.__version__}")
except Exception as e:
    print("âŒ æ— æ³•å¯¼å…¥ PyTorchï¼")
    print(e)
    sys.exit(1)

# æ£€æŸ¥ CUDA å¯ç”¨æ€§
cuda_available = torch.cuda.is_available()
print(f"âš™ï¸  CUDA æ˜¯å¦å¯ç”¨: {cuda_available}")

if cuda_available:
    device_count = torch.cuda.device_count()
    print(f"ğŸ§  æ£€æµ‹åˆ° GPU æ•°é‡: {device_count}")
    for i in range(device_count):
        print(f"   â”œâ”€â”€ GPU {i}: {torch.cuda.get_device_name(i)}")
    print("ğŸš€ æ­£åœ¨æµ‹è¯• GPU è®¡ç®—...")

    # æµ‹è¯•ä¸€æ¬¡å¼ é‡è®¡ç®—æ˜¯å¦çœŸçš„åœ¨ GPU ä¸Šæ‰§è¡Œ
    x = torch.rand(3, 3).to("cuda")
    y = torch.rand(3, 3).to("cuda")
    z = torch.mm(x, y)
    print("âœ… GPU çŸ©é˜µä¹˜æ³•æˆåŠŸï¼ç»“æœå¼ é‡ä½äº:", z.device)
else:
    print("âš ï¸ æœªæ£€æµ‹åˆ°å¯ç”¨çš„ CUDA GPUï¼Œæ­£åœ¨æµ‹è¯• CPU è®¡ç®—...")
    x = torch.rand(3, 3)
    y = torch.rand(3, 3)
    z = torch.mm(x, y)
    print("âœ… CPU è®¡ç®—æˆåŠŸã€‚ç»“æœå¼ é‡ä½äº:", z.device)

print("=" * 60)
print("ğŸ¯ æ£€æµ‹å®Œæˆï¼")
